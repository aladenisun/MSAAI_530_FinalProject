{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f5551e7d",
      "metadata": {
        "id": "f5551e7d"
      },
      "source": [
        "# LSTM Model\n",
        "\n",
        "This Long Short-Term Memory (LSTM) deep learning model is designed to learn and classify patterns in indoor air quality dynamics rather than identifying specific substances. Using time series data from three gas sensors along with temperature and humidity, the model captures how air conditions evolve over time during normal household activity and during events that degrade air quality, such as poor ventilation, cooking, or the presence of harmful gases. By modeling temporal dependencies, the LSTM can distinguish brief, harmless fluctuations from sustained or abnormal changes that may impact occupant health.\n",
        "\n",
        "The model runs in the cloud and processes incoming data in near real time, producing air quality state predictions that are smoothed over multiple windows before triggering alerts. Model performance is evaluated using classification metrics such as accuracy and F1-score, and results are visualized as predicted air quality states over time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "836f2c6f",
      "metadata": {
        "id": "836f2c6f"
      },
      "source": [
        "### Environment Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "59e6153e",
      "metadata": {
        "id": "59e6153e",
        "outputId": "1924b3f2-4357-40bd-96ef-d9a1bd005a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MSAAI_530_FinalProject'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 48 (delta 9), reused 29 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (48/48), 990.96 KiB | 3.20 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/aladenisun/MSAAI_530_FinalProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "22a618fa",
      "metadata": {
        "id": "22a618fa",
        "outputId": "edec3ed2-1543-4c10-9aff-34894d404c5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9b3549cb",
      "metadata": {
        "id": "9b3549cb"
      },
      "outputs": [],
      "source": [
        "!pip install -q -r /content/MSAAI_530_FinalProject/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "de58555e",
      "metadata": {
        "id": "de58555e",
        "outputId": "bd3dc54c-dd35-4ad8-b12b-06006cf36fca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using repo path: /content/MSAAI_530_FinalProject\n",
            "Using data path: /content/MSAAI_530_FinalProject/data\n",
            "CWD: /content/MSAAI_530_FinalProject\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "def in_colab():\n",
        "    return \"COLAB_GPU\" in os.environ or \"google.colab\" in sys.modules\n",
        "\n",
        "if in_colab():\n",
        "    # Running in Google Colab\n",
        "    repo_path = \"/content/MSAAI_530_FinalProject\"\n",
        "    data_path = \"/content/MSAAI_530_FinalProject/data\"\n",
        "\n",
        "    # Set working directory to the repo root\n",
        "    os.chdir(repo_path)\n",
        "\n",
        "else:\n",
        "    # Running locally in VS Code\n",
        "    repo_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "    data_path = os.path.abspath(os.path.join(repo_path, \"data\"))\n",
        "\n",
        "    # Add repo root to Python path\n",
        "    if repo_path not in sys.path:\n",
        "        sys.path.append(repo_path)\n",
        "\n",
        "    # Set working directory to the repo root\n",
        "    os.chdir(repo_path)\n",
        "\n",
        "print(\"Using repo path:\", repo_path)\n",
        "print(\"Using data path:\", data_path)\n",
        "print(\"CWD:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a3323182",
      "metadata": {
        "id": "a3323182"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0c401e4",
      "metadata": {
        "id": "f0c401e4"
      },
      "source": [
        "### Create Train, Validation, and Test Datasets\n",
        "\n",
        "We will train the model on a segment of our data and then measure its performance on simulated streaming data another segment of the data. Using a chronological 80/20 spilt for the training and validation sets. The test split will come from the training data as part of the tensorflow LSTM model call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6ffba77a",
      "metadata": {
        "id": "6ffba77a",
        "outputId": "b23c11d5-8132-4ac2-d151-28c9475cb9b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            R1       R2       R3     Temp  Humidity\n",
            "12810  13.0313  9.49602  9.56483  26.1461   56.9043\n",
            "12811  13.0312  9.49625  9.56518  26.1456   56.9057\n",
            "12812  13.0317  9.49630  9.56567  26.1450   56.9069\n",
            "12813  13.0313  9.49633  9.56628  26.1446   56.9080\n",
            "12814  13.0314  9.49603  9.56666  26.1441   56.9090\n",
            "(10252, 5)\n",
            "(2563, 5)\n"
          ]
        }
      ],
      "source": [
        "dataset_csv = os.path.join(data_path, \"Cleaned_HT_Sensor_Dataset.csv\")\n",
        "\n",
        "# Load CSVs\n",
        "df = pd.read_csv(dataset_csv, delimiter=\",\").dropna()\n",
        "\n",
        "# Focus on the first three sensors, temp, and humidity to match our system design\n",
        "feature_cols = [\"R1\", \"R2\", \"R3\", \"Temp\", \"Humidity\"]\n",
        "df_model = df[feature_cols].copy()\n",
        "\n",
        "print(df_model.tail())\n",
        "\n",
        "# Chronological 80/20 split\n",
        "split_idx = int(np.floor(0.8 * len(df_model)))\n",
        "\n",
        "train_df = df_model.iloc[:split_idx].reset_index(drop=True)\n",
        "val_df   = df_model.iloc[split_idx:].reset_index(drop=True)\n",
        "\n",
        "# Implemented scailing because of temp and humidity\n",
        "scaler = StandardScaler()\n",
        "train_scaled = scaler.fit_transform(train_df.values)\n",
        "val_scaled   = scaler.transform(val_df.values)\n",
        "\n",
        "print(train_scaled.shape)\n",
        "print(val_scaled.shape)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}