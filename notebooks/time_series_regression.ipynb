{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8bec14",
   "metadata": {},
   "source": [
    "# Traditional Time-Series Forecasting\n",
    "\n",
    "This notebook implements a traditional time-series prediction baseline for Smart Home Air Monitoring.\n",
    "\n",
    "**Goal:** Use the previous 30 seconds of readings from R1–R4 to predict (R3, R4) 10 seconds into the future.\n",
    "\n",
    "We frame forecasting as a supervised learning problem using sliding windows (lag features), then train and evaluate:\n",
    "- Linear Regression (baseline)\n",
    "- Ridge Regression (regularized baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7cbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_colab():\n",
    "    return \"COLAB_GPU\" in os.environ or \"google.colab\" in sys.modules\n",
    "\n",
    "if in_colab():\n",
    "    # Running in Google Colab\n",
    "    repo_path = \"/content/MSAAI_530_FinalProject\"\n",
    "    data_path = \"/content/MSAAI_530_FinalProject/data\"\n",
    "\n",
    "    # Set working directory to the repo root\n",
    "    os.chdir(repo_path)\n",
    "\n",
    "else:\n",
    "    # Running locally in VS Code\n",
    "    repo_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "    data_path = os.path.abspath(os.path.join(repo_path, \"data\"))\n",
    "\n",
    "    # Add repo root to Python path\n",
    "    if repo_path not in sys.path:\n",
    "        sys.path.append(repo_path)\n",
    "\n",
    "    # Set working directory to the repo root\n",
    "    os.chdir(repo_path)\n",
    "\n",
    "print(\"Using repo path:\", repo_path)\n",
    "print(\"Using data path:\", data_path)\n",
    "print(\"CWD:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and basic cleanup\n",
    "dataset_csv = os.path.join(data_path, \"Cleaned_HT_Sensor_Dataset.csv\")\n",
    "\n",
    "# Load CSVs\n",
    "df = pd.read_csv(dataset_csv, delimiter=\",\").sort_values([\"id\",\"time\"]).reset_index(drop=True)\n",
    "\n",
    "SENSOR_COLS = [\"R1\",\"R2\",\"R3\",\"R4\"]\n",
    "TARGET_COLS = [\"R3\", \"R4\"]\n",
    "cols_to_fill = sorted(set(SENSOR_COLS + TARGET_COLS))\n",
    "\n",
    "# Time-series setup\n",
    "WINDOW = 30   # past 30 seconds (lag window)\n",
    "HORIZON = 10  # predict 10 seconds into the future\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing sensor values within each recording using forward/back fill\n",
    "df[cols_to_fill] = (\n",
    "    df.groupby(\"id\")[cols_to_fill]\n",
    "      .apply(lambda g: g.ffill().bfill())\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "# Confirm no missing values remain for modeled columns\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Missing values per column:\")\n",
    "print(df[SENSOR_COLS].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3402a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data\n",
    "df.isna().sum().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f3630",
   "metadata": {},
   "source": [
    "## 1. Convert time series to supervised learning (sliding windows)\n",
    "\n",
    "For each recording id, we create many training examples:\n",
    "- Input (X): the past window seconds of sensor readings (flattened)\n",
    "- Target (y): the sensor value at horizon seconds into the future\n",
    "\n",
    "This is the standard way to use traditional ML models for forecasting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d3ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(group: pd.DataFrame, feature_cols, target_col, window=30, horizon=10):\n",
    "    \"\"\"Create supervised learning samples from one recording (one id).\n",
    "\n",
    "    X: [num_samples, window * num_features]\n",
    "    y: [num_samples,]\n",
    "    t: target timestamps (for plotting)\n",
    "    \"\"\"\n",
    "    X_list, y_list, t_list = [], [], []\n",
    "    Xdata = group[feature_cols].to_numpy()\n",
    "    ydata = group[target_col].to_numpy()\n",
    "    times = group[\"time\"].to_numpy()\n",
    "\n",
    "    n = len(group)\n",
    "    max_start = n - window - horizon + 1\n",
    "\n",
    "    for start in range(max_start):\n",
    "        end = start + window\n",
    "        target_idx = end + horizon - 1\n",
    "        X_list.append(Xdata[start:end].reshape(-1))\n",
    "        y_list.append(ydata[target_idx])\n",
    "        t_list.append(times[target_idx])\n",
    "\n",
    "    return np.array(X_list), np.array(y_list), np.array(t_list)\n",
    "\n",
    "print(\"Window function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e8a44",
   "metadata": {},
   "source": [
    "## 2. Train/Test split (time-aware)\n",
    "\n",
    "To avoid data leakage, we split within each recording in time order:\n",
    "- First 70% of windows -> training\n",
    "- Last 30% of windows -> testing\n",
    "\n",
    "This mimics real forecasting (training on earlier behavior, testing on later behavior).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a360f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list, y_train_list = [], []\n",
    "X_test_list, y_test_list = [], []\n",
    "meta_test = []  # (id, time) for plotting\n",
    "\n",
    "for gid, g in df.groupby(\"id\"):\n",
    "    g = g.reset_index(drop=True)\n",
    "    X, y, t = make_windows(g, SENSOR_COLS, TARGET_COLS, window=WINDOW, horizon=HORIZON)\n",
    "\n",
    "    # Skip very short recordings\n",
    "    if len(X) < 50:\n",
    "        continue\n",
    "\n",
    "    split = int(len(X) * 0.7)\n",
    "    X_train_list.append(X[:split])\n",
    "    y_train_list.append(y[:split])\n",
    "\n",
    "    X_test_list.append(X[split:])\n",
    "    y_test_list.append(y[split:])\n",
    "    meta_test.extend([(gid, ti) for ti in t[split:]])\n",
    "\n",
    "X_train = np.vstack(X_train_list)\n",
    "y_train = np.vstack(y_train_list)\n",
    "X_test = np.vstack(X_test_list)\n",
    "y_test = np.vstack(y_test_list)\n",
    "\n",
    "print(\"Train X:\", X_train.shape, \"Train y:\", y_train.shape)\n",
    "print(\"Test  X:\", X_test.shape,  \"Test  y:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69837d27",
   "metadata": {},
   "source": [
    "## 3. Train traditional forecasting models\n",
    "\n",
    "We train two lightweight regression baselines:\n",
    "1. **Linear Regression**: simplest interpretable baseline\n",
    "2. **Ridge Regression**: linear regression with L2 regularization (helps reduce overfitting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776ec73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_target_metrics(y_true, y_pred, target_names):\n",
    "    rows = []\n",
    "    for i, name in enumerate(target_names):\n",
    "        mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n",
    "        rmse = mean_squared_error(y_true[:, i], y_pred[:, i]) ** 0.5\n",
    "        r2 = r2_score(y_true[:, i], y_pred[:, i])\n",
    "\n",
    "        rows.append({\"Target\": name, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2})\n",
    "\n",
    "    # Add overall average row (so your summary code works)\n",
    "    rows.append({\n",
    "        \"Target\": \"OVERALL_AVG\",\n",
    "        \"MAE\": np.mean([r[\"MAE\"] for r in rows]),\n",
    "        \"RMSE\": np.mean([r[\"RMSE\"] for r in rows]),\n",
    "        \"R2\": np.mean([r[\"R2\"] for r in rows]),\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\": Pipeline([(\"scaler\", StandardScaler()), (\"model\", LinearRegression())]),\n",
    "    \"Ridge(alpha=1.0)\": Pipeline([(\"scaler\", StandardScaler()), (\"model\", Ridge(alpha=1.0))])\n",
    "}\n",
    "\n",
    "preds = {}\n",
    "all_metrics = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    preds[name] = y_pred\n",
    "    all_metrics[name] = per_target_metrics(y_test, y_pred, TARGET_COLS)\n",
    "\n",
    "# Overall comparison table\n",
    "summary = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": name,\n",
    "        \"MAE (avg)\": all_metrics[name].loc[all_metrics[name][\"Target\"]==\"OVERALL_AVG\", \"MAE\"].values[0],\n",
    "        \"RMSE (avg)\": all_metrics[name].loc[all_metrics[name][\"Target\"]==\"OVERALL_AVG\", \"RMSE\"].values[0],\n",
    "        \"R2 (avg)\": all_metrics[name].loc[all_metrics[name][\"Target\"]==\"OVERALL_AVG\", \"R2\"].values[0],\n",
    "    }\n",
    "    for name in all_metrics\n",
    "]).sort_values(\"RMSE (avg)\")\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d2dd1",
   "metadata": {},
   "source": [
    "## 4. Plot predicted vs actual\n",
    "\n",
    "We plot predictions on a single test recording to show how well the model tracks the sensor trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc5a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame(meta_test, columns=[\"id\", \"time\"])\n",
    "meta[\"actual_R3\"] = y_test[:, 0]\n",
    "meta[\"actual_R4\"] = y_test[:, 1]\n",
    "\n",
    "meta[\"pred_linreg_R3\"] = preds[\"LinearRegression\"][:, 0]\n",
    "meta[\"pred_linreg_R4\"] = preds[\"LinearRegression\"][:, 1]\n",
    "\n",
    "meta[\"pred_ridge_R3\"] = preds[\"Ridge(alpha=1.0)\"][:, 0]\n",
    "meta[\"pred_ridge_R4\"] = preds[\"Ridge(alpha=1.0)\"][:, 1]\n",
    "\n",
    "chosen_id = meta[\"id\"].value_counts().idxmax()\n",
    "sub = meta[meta[\"id\"] == chosen_id].sort_values(\"time\").head(600)\n",
    "\n",
    "# Plot R3\n",
    "plt.figure()\n",
    "plt.plot(sub[\"time\"], sub[\"actual_R3\"], label=\"Actual R3\")\n",
    "plt.plot(sub[\"time\"], sub[\"pred_linreg_R3\"], label=\"Predicted R3 (LinearRegression)\")\n",
    "plt.plot(sub[\"time\"], sub[\"pred_ridge_R3\"], label=\"Predicted R3 (Ridge)\")\n",
    "plt.xlabel(\"Time (hours from induction start)\")\n",
    "plt.ylabel(\"R3 sensor resistance\")\n",
    "plt.title(f\"{HORIZON}-second-ahead forecast — R3 (Recording id={chosen_id})\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"forecast_R3.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Plot R4\n",
    "plt.figure()\n",
    "plt.plot(sub[\"time\"], sub[\"actual_R4\"], label=\"Actual R4\")\n",
    "plt.plot(sub[\"time\"], sub[\"pred_linreg_R4\"], label=\"Predicted R4 (LinearRegression)\")\n",
    "plt.plot(sub[\"time\"], sub[\"pred_ridge_R4\"], label=\"Predicted R4 (Ridge)\")\n",
    "plt.xlabel(\"Time (hours from induction start)\")\n",
    "plt.ylabel(\"R4 sensor resistance\")\n",
    "plt.title(f\"{HORIZON}-second-ahead forecast — R4 (Recording id={chosen_id})\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"forecast_R4.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved plots: forecast_R3.png, forecast_R4.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7880b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plots\n",
    "residuals_R3 = sub[\"actual_R3\"] - sub[\"pred_linreg_R3\"]\n",
    "residuals_R4 = sub[\"actual_R4\"] - sub[\"pred_linreg_R4\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sub[\"time\"], residuals_R3)\n",
    "plt.axhline(0)\n",
    "plt.title(\"Residuals over time — R3\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Error (Actual - Predicted)\")\n",
    "plt.savefig(\"Resduals_R3.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sub[\"time\"], residuals_R4)\n",
    "plt.axhline(0)\n",
    "plt.title(\"Residuals over time — R4\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Error (Actual - Predicted)\")\n",
    "plt.savefig(\"Resduals_R4.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved plots: Resduals_R3.png, Resduals_R4.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a8e74",
   "metadata": {},
   "source": [
    "## 5. Real time feasibility\n",
    "\n",
    "Because linear models are computationally lightweight, this approach is realistic for edge/gateway deployment:\n",
    "- The device only keeps the most recent window seconds of readings in memory.\n",
    "- Each prediction is a fast matrix operation (milliseconds on typical hardware).\n",
    "- Results can be sent to the cloud/mobile app for visualization and alerting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
